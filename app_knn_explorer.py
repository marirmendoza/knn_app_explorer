import streamlit as st
import numpy as np
import matplotlib.pyplot as plt
from sklearn.neighbors import KNeighborsClassifier
from sklearn.datasets import make_blobs, make_moons
from sklearn.preprocessing import MinMaxScaler


# ============================================================
# CABE√áALHO INSTITUCIONAL
# ============================================================

st.markdown("""
<div style="background-color:#f0f2f6; padding:15px; border-radius:10px; border-left: 5px solid #004a99;">
    <strong>Aprendizado de M√°quina ‚Äì Profa. Mariana Recamonde Mendoza</strong><br>
    Instituto de Inform√°tica, Universidade Federal do Rio Grande do Sul (UFRGS).<br>
    <em>Material interativo desenvolvido com apoio de IA generativa (ChatGPT + Gemini).</em>
</div>
""", unsafe_allow_html=True)

st.title("üîç Explorador Interativo do kNN ‚Äî Intui√ß√£o, Vizinhan√ßa e Escala")

st.markdown("""
O algoritmo **k-Nearest Neighbors (kNN)** se apoia em um princ√≠pio muito simples e poderoso:

> **Pontos semelhantes tendem a estar pr√≥ximos no espa√ßo.**

Esse √© o chamado **Vi√©s Indutivo de Suavidade Local**:  
se dois pontos t√™m atributos parecidos, espera-se que perten√ßam √† mesma classe.  

Este explorador permite visualizar, de maneira totalmente interativa:

- O efeito do valor de **k**  
- Como a **escala dos atributos** muda completamente a fronteira  
- Como diferentes **m√©tricas de dist√¢ncia** deformam as regi√µes de decis√£o  
- O impacto da **normaliza√ß√£o**  
- E at√© um pequeno teste com pontos "desconhecidos"  
""")


# ============================================================
# SIDEBAR ‚Äì CONFIGURA√á√ïES
# ============================================================

st.sidebar.header("üõ†Ô∏è Configura√ß√µes do kNN")
k = st.sidebar.slider("Valor de k (Vizinhos)", 1, 31, 3, step=2)
metric = st.sidebar.selectbox("M√©trica de Dist√¢ncia", ["euclidean", "manhattan"])

st.sidebar.markdown("---")

scenario = st.sidebar.radio("Cen√°rio de Explora√ß√£o:", [
    "Fronteira Local (k=1 vs k=25)",
    "Impacto da Escala",
    "Diferentes M√©tricas"
])

dataset_type = st.sidebar.selectbox("Base de Dados", ["Moons", "Blobs"])

normalize = st.sidebar.checkbox("Ativar Normaliza√ß√£o", value=False)


# ============================================================
# 1. DATASET BASE PERSISTENTE
# ============================================================

def generate_base_data(dataset):
    if dataset == "Moons":
        return make_moons(n_samples=300, noise=0.20, random_state=42)
    else:
        return make_blobs(n_samples=300, centers=2, cluster_std=1.2, random_state=42)

# dataset √© sempre o MESMO para todos os cen√°rios
X_base, y_base = generate_base_data(dataset_type)

# trabalhamos sobre c√≥pia, n√£o sobre o original
X = X_base.copy()
y = y_base.copy()


# ============================================================
# 2. APLICA√á√ÉO DO CEN√ÅRIO ESCOLHIDO
# ============================================================

if scenario == "Fronteira Local (k=1 vs k=25)":
    info = (
        "Com k=1 surgem pequenas 'ilhas' ao redor de cada amostra ‚Äî "
        "**overfitting local**. Com k=25, a fronteira se torna muito mais suave."
    )

elif scenario == "Impacto da Escala":
    X[:, 1] *= 50
    info = (
        "O eixo Y foi multiplicado por 50 ‚Äî sem normaliza√ß√£o a dist√¢ncia "
        "vertical domina completamente a classifica√ß√£o."
    )

elif scenario == "Diferentes M√©tricas":
    if dataset_type == "Moons":
        X[:, 0] *= 2
        X[:, 1] *= 0.5
    else:
        X, y = make_blobs(
            n_samples=300,
            centers=2,
            cluster_std=2.0,
            random_state=10
        )
    info = (
        "A dist√¢ncia Euclidiana (L2) tende a gerar fronteiras circulares; "
        "a Manhattan (L1) cria fronteiras mais retangulares ou losangulares."
    )


# ============================================================
# 3. NORMALIZA√á√ÉO
# ============================================================

if normalize:
    scaler = MinMaxScaler()
    X_model = scaler.fit_transform(X)
else:
    X_model = X


# ============================================================
# 4. TREINO DO MODELO
# ============================================================

clf = KNeighborsClassifier(n_neighbors=k, metric=metric)
clf.fit(X_model, y)


# ============================================================
# 5. GERA√á√ÉO DO GRID PARA A FRONTEIRA
# ============================================================

h = 0.1
x_min, x_max = X_model[:, 0].min() - 0.5, X_model[:, 0].max() + 0.5
y_min, y_max = X_model[:, 1].min() - 0.5, X_model[:, 1].max() + 0.5

xx, yy = np.meshgrid(
    np.arange(x_min, x_max, h),
    np.arange(y_min, y_max, h),
)

Z = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)


# ============================================================
# 6. VISUALIZA√á√ÉO PRINCIPAL
# ============================================================

fig, ax = plt.subplots(figsize=(10, 6))
ax.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')
ax.scatter(X_model[:, 0], X_model[:, 1], c=y, edgecolors='k', cmap='RdBu', alpha=0.8)
ax.set_title(f"Fronteira de Decis√£o (k={k}, M√©trica={metric})")

st.pyplot(fig)
st.info(f"**Insight:** {info}")


# ============================================================
# 7. TESTE COM PONTOS DESCONHECIDOS (Generaliza√ß√£o)
# ============================================================

st.markdown("---")
st.subheader("üìä Teste com Pontos Desconhecidos")

def generate_test_points(dataset):
    if dataset == "Moons":
        return make_moons(n_samples=10, noise=0.25, random_state=7)
    else:
        return make_blobs(
            n_samples=10,
            centers=2,
            cluster_std=1.2,
            random_state=15
        )

if "test_points" not in st.session_state:
    st.session_state.test_points = generate_test_points(dataset_type)

X_test, y_test = st.session_state.test_points

point_idx = st.selectbox("Selecione o ponto de teste:", range(10), format_func=lambda x: f"Ponto {x+1}")

test_raw = X_test[point_idx].reshape(1, -1)
test_point = scaler.transform(test_raw) if normalize else test_raw

pred = clf.predict(test_point)[0]
real = y_test[point_idx]

status = "‚úÖ ACERTO" if pred == real else "‚ùå ERRO"
st.metric("Resultado da Predi√ß√£o", status)
st.write(f"**Classe Predita:** {pred}")
st.write(f"**Classe Real:** {real}")


# Plot dos pontos de teste
fig_test, ax_test = plt.subplots(figsize=(8, 4))
ax_test.contourf(xx, yy, Z, alpha=0.3, cmap='RdBu')
ax_test.scatter(X_model[:, 0], X_model[:, 1], c=y, cmap='RdBu', alpha=0.3)

for i in range(10):
    p = X_test[i].reshape(1, -1)
    if normalize:
        p = scaler.transform(p)

    ax_test.scatter(
        p[0, 0], p[0, 1],
        s=180 if i == point_idx else 60,
        marker='X' if i == point_idx else 'o',
        c='yellow' if i == point_idx else 'black',
        edgecolors='black'
    )

ax_test.set_title("Pontos de Teste (Desconhecidos)")
st.pyplot(fig_test)

# acur√°cia simples
test_model = scaler.transform(X_test) if normalize else X_test
acc = np.mean(clf.predict(test_model) == y_test)

st.write(f"**Taxa de Acerto nos 10 Pontos:** `{acc:.0%}`")
